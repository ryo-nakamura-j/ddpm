train:
  batch_size:       64
  num_time_steps:   1000
  num_epochs:       100
  seed:             42
  ema_decay:        0.9999
  lr:               0.0001
  save_every:       5           # save every N epochs
  checkpoint_dir:   "Models/checkpoints_mid"
  # checkpoint_path:  "Models/checkpoints/celeba_epoch_20.pth"
  checkpoint_prefix: "celeba_mid"
  log_dir:          "Models/tensorboard_mid"